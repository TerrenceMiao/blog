---
title: 'AWS EKS on Fargate, with eksctl'
date: 2019-12-07 22:33:38
tags:
---

AWS EKS, with eksctl
--------------------

Second try with AWS EKS on Fargate. This time with `eksctl`.

Create EKS cluster:

```console
ùúÜ eksctl create cluster --name sandpit --version 1.14 --region us-east-2 --fargate
[‚Ñπ]  eksctl version 0.11.1
[‚Ñπ]  using region us-east-2
[‚Ñπ]  setting availability zones to [us-east-2b us-east-2a us-east-2c]
[‚Ñπ]  subnets for us-east-2b - public:192.168.0.0/19 private:192.168.96.0/19
[‚Ñπ]  subnets for us-east-2a - public:192.168.32.0/19 private:192.168.128.0/19
[‚Ñπ]  subnets for us-east-2c - public:192.168.64.0/19 private:192.168.160.0/19
[‚Ñπ]  using Kubernetes version 1.14
[‚Ñπ]  creating EKS cluster "sandpit" in "us-east-2" region with Fargate profile
[‚Ñπ]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-2 --cluster=sandpit'
[‚Ñπ]  CloudWatch logging will not be enabled for cluster "sandpit" in "us-east-2"
[‚Ñπ]  you can enable it with 'eksctl utils update-cluster-logging --region=us-east-2 --cluster=sandpit'
[‚Ñπ]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "sandpit" in "us-east-2"
[‚Ñπ]  1 task: { create cluster control plane "sandpit" }
[‚Ñπ]  building cluster stack "eksctl-sandpit-cluster"
[‚Ñπ]  deploying stack "eksctl-sandpit-cluster"
[‚úî]  all EKS cluster resources for "sandpit" have been created
[‚úî]  saved kubeconfig as "/Users/terrence/.kube/config"
[‚Ñπ]  creating Fargate profile "fp-default" on EKS cluster "sandpit"
[‚Ñπ]  created Fargate profile "fp-default" on EKS cluster "sandpit"
[‚Ñπ]  "coredns" is now schedulable onto Fargate
[‚Ñπ]  "coredns" is now scheduled onto Fargate
[‚Ñπ]  "coredns" pods are now scheduled onto Fargate
[‚Ñπ]  kubectl command should work with "/Users/terrence/.kube/config", try 'kubectl get nodes'
[‚úî]  EKS cluster "sandpit" in "us-east-2" region is ready
```

![AWS EKS on Fargate, with eksctl - Cluster](/blog/img/AWS%20EKS%20on%20Fargate,%20with%20eksctl%20-%20Cluster.png "AWS EKS on Fargate, with eksctl - Cluster")

Create and add EKS mansged node group:

```console
ùúÜ eksctl create nodegroup --cluster sandpit --name workers --node-type t3a.medium --ssh-access --ssh-public-key aws-us-key --managed
[‚Ñπ]  eksctl version 0.11.1
[‚Ñπ]  using region us-east-2
[‚Ñπ]  will use version 1.14 for new nodegroup(s) based on control plane version
[‚Ñπ]  using EC2 key pair %!!(MISSING)q(*string=<nil>)
[‚Ñπ]  1 nodegroup (workers) was included (based on the include/exclude rules)
[‚Ñπ]  will create a CloudFormation stack for each of 1 managed nodegroups in cluster "sandpit"
[‚Ñπ]  1 task: { 1 task: { create managed nodegroup "workers" } }
[‚Ñπ]  building managed nodegroup stack "eksctl-sandpit-nodegroup-workers"
[‚Ñπ]  deploying stack "eksctl-sandpit-nodegroup-workers"
[‚úî]  created 0 nodegroup(s) in cluster "sandpit"
[‚Ñπ]  nodegroup "workers" has 2 node(s)
[‚Ñπ]  node "ip-192-168-47-175.us-east-2.compute.internal" is ready
[‚Ñπ]  node "ip-192-168-87-98.us-east-2.compute.internal" is ready
[‚Ñπ]  waiting for at least 2 node(s) to become ready in "workers"
[‚Ñπ]  nodegroup "workers" has 2 node(s)
[‚Ñπ]  node "ip-192-168-47-175.us-east-2.compute.internal" is ready
[‚Ñπ]  node "ip-192-168-87-98.us-east-2.compute.internal" is ready
[‚úî]  created 1 managed nodegroup(s) in cluster "sandpit"
[‚Ñπ]  checking security group configuration for all nodegroups
[‚Ñπ]  all nodegroups have up-to-date configuration
```

Install Kubernetes Dashboard:

```console
ùúÜ kubectl get services  --all-namespaces
NAMESPACE              NAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE
default                kubernetes                  ClusterIP   10.100.0.1       <none>        443/TCP         70m
kube-system            kube-dns                    ClusterIP   10.100.0.10      <none>        53/UDP,53/TCP   70m
kube-system            metrics-server              ClusterIP   10.100.142.106   <none>        443/TCP         14m
kubernetes-dashboard   dashboard-metrics-scraper   ClusterIP   10.100.91.78     <none>        8000/TCP        11m
kubernetes-dashboard   kubernetes-dashboard        ClusterIP   10.100.75.0      <none>        443/TCP         11m

ùúÜ kubectl get pods  --all-namespaces
NAMESPACE              NAME                                         READY   STATUS    RESTARTS   AGE
kube-system            aws-node-cnzrv                               1/1     Running   0          40m
kube-system            aws-node-m9tjp                               1/1     Running   0          40m
kube-system            coredns-7f5cccffc-h44mz                      1/1     Running   0          65m
kube-system            coredns-7f5cccffc-hmx7g                      1/1     Running   0          65m
kube-system            kube-proxy-7kn62                             1/1     Running   0          40m
kube-system            kube-proxy-g57ph                             1/1     Running   0          40m
kube-system            metrics-server-7fcf9cc98b-ftl4k              1/1     Running   0          14m
kubernetes-dashboard   dashboard-metrics-scraper-677768c755-mxlmc   1/1     Running   0          11m
kubernetes-dashboard   kubernetes-dashboard-995fd6fb4-xqcj5         1/1     Running   0          11m
```

Connect Kubernetes Dashboard via proxy:

```console
ùúÜ cat .kube/config
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /Users/terrence/.minikube/ca.crt
    server: https://192.168.99.100:8443
  name: minikube
- cluster:
    certificate-authority-data: LS0tLS1CRUd ... tLS0tLQo=
    server: https://0559DE89F43B8766B56C7FD066C6C50F.yl4.us-east-2.eks.amazonaws.com
  name: sandpit.us-east-2.eksctl.io
contexts:
- context:
    cluster: sandpit.us-east-2.eksctl.io
    user: ADMMiaoT@sandpit.us-east-2.eksctl.io
  name: ADMMiaoT@sandpit.us-east-2.eksctl.io
- context:
    cluster: minikube
    user: minikube
  name: minikube
current-context: ADMMiaoT@sandpit.us-east-2.eksctl.io
kind: Config
preferences: {}
users:
- name: ADMMiaoT@sandpit.us-east-2.eksctl.io
  user:
    exec:
      apiVersion: client.authentication.k8s.io/v1alpha1
      args:
      - token
      - -i
      - sandpit
      command: aws-iam-authenticator
      env:
      - name: AWS_PROFILE
        value: paradise-dev
- name: minikube
  user:
    client-certificate: /Users/terrence/.minikube/client.crt
    client-key: /Users/terrence/.minikube/client.key

ùúÜ kubectl -n kube-system get secret | grep eks-admin | awk '{print $1}'
eks-admin-token-s2gf5

ùúÜ kubectl -n kube-system describe secret eks-admin-token-s2gf5
Name:         eks-admin-token-s2gf5
Namespace:    kube-system
Labels:       <none>
Annotations:  kubernetes.io/service-account.name: eks-admin
              kubernetes.io/service-account.uid: fa3cf514-18bc-11ea-bbdd-0a4cd5e8dc70

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1025 bytes
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIs ... hpY8upQlA2q40g

ùúÜ kubectl proxy
```

Visit URL _http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#!/login_

Choose Token, paste the token output from the previous command into the Token field, and choose SIGN IN.

![AWS EKS on Fargate, with eksctl - Nodes](/blog/img/AWS%20EKS%20on%20Fargate,%20with%20eksctl%20-%20Nodes.png "AWS EKS on Fargate, with eksctl - Nodes")

With AWS managed nodes, on Node EC2 instance:

![AWS EKS on Fargate, with eksctl - EC2 instance](/blog/img/AWS%20EKS%20on%20Fargate,%20with%20eksctl%20-%20EC2%20instance.png "AWS EKS on Fargate, with eksctl - EC2 instance")

References
----------

- `eksctl`, a simple CLI tool for creating clusters on Amazon‚Äôs new managed Kubernetes service for EC2 - EKS. Written in Go, uses CloudFormation, _https://eksctl.io/_
- AWS EKS, _https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html_